"""Protocol definitions for the AI API services.

This module defines the protocols (interfaces) that various services must implement
to provide AI-related functionality such as embedding generation, image processing,
and search operations.
"""

from __future__ import annotations

from typing import TYPE_CHECKING, Any, Protocol, runtime_checkable

if TYPE_CHECKING:
    from collections.abc import Callable, Coroutine

    from _bentoml_sdk.method import APIMethod
    from bentoml import Context
    from fastapi.responses import JSONResponse
    from loguru._logger import Logger
    from PIL.Image import Image as PILImage

    from .image_search import ImageSearchResponse
    from .process import AIGeneratedStatus
    from .query_search import SearchResponse


@runtime_checkable
class InferenceServiceProto(Protocol):
    """Protocol for inference service operations.

    This protocol defines the interface that inference services must implement
    to provide AI operations like embedding generation and image processing.
    """

    async def embed_text(self, texts: list[str]) -> list[list[float]]:
        """Generate embeddings for a list of text inputs.

        :param texts: List of text strings to embed.
        :type texts: list[str]
        :returns: List of normalized embedding vectors.
        :rtype: list[list[float]]
        """
        ...

    async def embed_image(self, images: list[PILImage]) -> list[list[float]]:
        """Generate embeddings for a list of images.

        :param images: List of PIL images to embed.
        :type images: list[PILImage]
        :returns: List of normalized embedding vectors.
        :rtype: list[list[float]]
        """
        ...

    async def generate_caption(self, images: list[PILImage]) -> list[str]:
        """Generate descriptive captions for a list of images.

        :param images: List of PIL images to generate captions for.
        :type images: list[PILImage]
        :returns: List of generated caption strings.
        :rtype: list[str]
        """
        ...

    async def detect_ai_generation(self, images: list[PILImage]) -> list[AIGeneratedStatus]:
        """Detect whether images were generated by AI.

        :param images: List of PIL images to check.
        :type images: list[PILImage]
        :returns: List of AI generation status enums.
        :rtype: list[AIGeneratedStatus]
        """
        ...

    async def check_ai_watermark(self, images: list[PILImage]) -> list[bool]:
        """Check for the presence of AI-specific watermarks in images.

        :param images: List of PIL images to check for AI watermarks.
        :type images: list[PILImage]
        :returns: List of boolean values indicating AI watermark presence.
        :rtype: list[bool]
        """
        ...

    async def add_ai_watermark(self, images: list[PILImage], prompts: list[str]) -> list[PILImage]:
        """Add AI-specific watermarks to a list of images.

        :param images: List of PIL images to add AI watermarks to.
        :type images: list[PILImage]
        :param prompts: List of prompts to guide the watermarking process.
        :type prompts: list[str]
        :returns: List of watermarked PIL images.
        :rtype: list[PILImage]
        """
        ...


class APIServiceProto(Protocol):
    """Protocol defining the interface for the main API service.

    This protocol defines the required attributes and methods for the main API
    service, including:
    - Health and readiness checks
    - Search operations (text and image-based)
    - Image processing operations

    The service coordinates between the inference service, database, and external
    services to provide the complete API functionality.

    Attributes:
        db_healthy: Flag indicating database health status.
        embedding_service: Reference to the inference service.
        ctx: BentoML context for request handling.
        logger: Logger instance for service logging.
        hash_fn: Function to generate perceptual hashes.
        hash_threshold: Threshold for hash similarity comparison.

    """

    db_healthy: bool
    embedding_service: InferenceServiceProto
    ctx: Context
    logger: Logger
    hash_fn: Callable[[PILImage], Any]
    hash_threshold: float

    healthz: Callable[[Any], Coroutine[Any, Any, JSONResponse]]

    readyz: Callable[[Any], Coroutine[Any, Any, JSONResponse]]

    search_query: Callable[
        [Any, str, int, int],
        Coroutine[Any, Any, SearchResponse],
    ]

    search_image: Callable[
        [Any, str, int, int],
        Coroutine[Any, Any, ImageSearchResponse],
    ]

    process_image: APIMethod[
        [PILImage, str, str, dict[str, Any], Context],
        Coroutine[Any, Any, None],
    ]

    embed_text: APIMethod[
        [list[str]],
        Coroutine[Any, Any, list[list[float]]],
    ]

    embed_image: APIMethod[
        [list[PILImage]],
        Coroutine[Any, Any, list[list[float]]],
    ]

    generate_caption: APIMethod[
        [list[PILImage]],
        Coroutine[Any, Any, list[str]],
    ]

    detect_ai_generation: APIMethod[
        [list[PILImage]],
        Coroutine[Any, Any, list[AIGeneratedStatus]],
    ]

    check_ai_watermark: APIMethod[
        [list[PILImage]],
        Coroutine[Any, Any, list[bool]],
    ]

    add_ai_watermark: APIMethod[
        [list[PILImage], list[str]],
        Coroutine[Any, Any, list[PILImage]],
    ]
